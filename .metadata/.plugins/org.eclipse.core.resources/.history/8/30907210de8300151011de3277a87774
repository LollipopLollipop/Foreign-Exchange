/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.*;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.cassandra.db.IColumn;
import org.apache.cassandra.hadoop.ColumnFamilyInputFormat;
import org.apache.cassandra.hadoop.ConfigHelper;
import org.apache.cassandra.thrift.*;
import org.apache.cassandra.utils.ByteBufferUtil;

/**
 * This sums the word count stored in the input_words_count ColumnFamily for the key "key-if-verse1".
 *
 * Output is written to a text file.
 */
public class MRRandomForest extends Configured implements Tool
{
    private static final Logger logger = LoggerFactory.getLogger(MRRandomForest.class);
    static final String KEYSPACE = "randomforest";
    static final String COLUMN_FAMILY = "forex_data";
    private static final List<Integer> totalFeatures = Arrays.asList(0, 1, 2, 3);
    private static final String OUTPUT_PATH_PREFIX = "randomforest_model";


    public static void main(String[] args) throws Exception
    {
        // Let ToolRunner handle generic command-line options
        ToolRunner.run(new Configuration(), new MRRandomForest(), args);
        System.exit(0);
    }

    public static class SumMapper extends Mapper<ByteBuffer, SortedMap<ByteBuffer, IColumn>, Text, LongWritable>
    {
        public void map(ByteBuffer key, SortedMap<ByteBuffer, IColumn> columns, Context context) throws IOException, InterruptedException
        {
        	//randomly select subset of about âˆš(# of features)
			Collections.shuffle(totalFeatures);
			//4 features in current data format, square root of 4 is 2
			List<Integer> usedFeatures = totalFeatures.subList(0, 2);
			ArrayList<CandleStick> trainInstances = 
					new ArrayList<CandleStick>();
			ArrayList<CandleStick> testInstances = 
					new ArrayList<CandleStick>();
			int count = 0;
            for (IColumn column : columns.values())
            {
                logger.debug("read " + key + ":" + column.name() + " from " + context.getInputSplit());
                sum += ByteBufferUtil.toLong(column.value());
            }
            context.write(new Text(ByteBufferUtil.string(key)), new LongWritable(sum));
            
            
			DecisionTree dt = new DecisionTree(trainInstances, usedFeatures);
			//build the tree
			dt.train();
			//predict labels for testing instances based on the d-tree
			ArrayList<Integer> predictedLabels = dt.classify(testInstances);
			//get the performance stats
			int matchCount = 0;
			int j = 0;
			for(CandleStick ins : testInstances){
				if(ins.getLabel() == predictedLabels.get(j++))
					matchCount++;
			}
			double accuracy = (double)matchCount/((double)j);
			
			
        }
    }

    public int run(String[] args) throws Exception
    {
        Job job = new Job(getConf(), "wordcountcounters");
        job.setJarByClass(MRRandomForest.class);
        job.setMapperClass(SumMapper.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(LongWritable.class);
        FileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH_PREFIX));


        job.setInputFormatClass(ColumnFamilyInputFormat.class);


        ConfigHelper.setInputRpcPort(job.getConfiguration(), "9160");
        ConfigHelper.setInputInitialAddress(job.getConfiguration(), "localhost");
        ConfigHelper.setInputPartitioner(job.getConfiguration(), "org.apache.cassandra.dht.RandomPartitioner");
        ConfigHelper.setInputColumnFamily(job.getConfiguration(), WordCount.KEYSPACE, MRRandomForest.COUNTER_COLUMN_FAMILY);
        SlicePredicate predicate = new SlicePredicate().setSlice_range(
                                                                        new SliceRange().
                                                                        setStart(ByteBufferUtil.EMPTY_BYTE_BUFFER).
                                                                        setFinish(ByteBufferUtil.EMPTY_BYTE_BUFFER).
                                                                        setCount(100));
        ConfigHelper.setInputSlicePredicate(job.getConfiguration(), predicate);

        job.waitForCompletion(true);
        return 0;
    }
}
